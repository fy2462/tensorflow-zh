# TensorBoard:可视化学习　<a class="md-anchor" id="AUTOGENERATED-tensorboard--visualizing-learning"></a>
TensorBoard涉及到的运算通常是训练庞大的深度神经网络这样复杂而又难以理解的运算。为了更方便
TensorFlow程序的  
理解，调试与优化，我们发布了一套叫做TensorFlow的可视化工具。你可以用
TensorBoard来显示你的TensorFlow图像  
，划分不同完成度的图像，。当TensorBoard设置完成后，它应该是这样子的：
![MNIST TensorBoard](../images/mnist_tensorboard.png )
#串行数据　<a class="md-anchor" id="AUTOGENERATED-serializing-the-data"></a>
TensorBoard通过读取TensorFlow的事件来运行。TensorFlow的事件文件包括了你会在TensorFlow的运行中设计到的所  
有数据。下面是这些数据在TensorBoard中一般的生命周期。

首先，创建你想汇总数据的TensorFlow图，然后再选择你想在哪个节点进行[汇总操作](../api_docs/python/train.md#summary_options)。

比如，假设你正在训练一个用来识别MNISt标签。你可能希望记录每次学习率的变化，以及目标函数是怎么变化的。通过  
向节点附加[scalar_summary](../api_docs/python/train.md#scalary_summary)运算来分别输出学习率和期望误差。然后你可以给每一个scalary_summary一个有意义的  
`标签`，比如`'learning rate'`和`'loss function'`。

或者你还希望显示一个特殊层中激活的分布，或者梯度权重的分布。通过分别附加  [histogram_summary](../api_docs/python/train.md#histogram_summary)运算来收集权重变  
量和梯度输出。

所有可用的summary操作，可以查看[summary_operation](../api_docs/python/train.md#summary_operation)文档。

在TensorFlow中，所有的操作只有当你执行，或者另一个操作依赖于它的输出时才会运行。我们刚才创建的这些简标都围  
绕着你的图像：没有任何操作依赖于它们的结果。因此，为了生成汇总信息，我们需要运行所有的节点。这样的手动工作  
是很乏味的，因此可以使用[tf.merge_all_summaries](../api_docs/python/train.md#scalary_summary)来将他们合并为一个操作。

然后你可以执行整合之后的汇总命令。这会在一定步骤之后通过你的数据生成一个有序的`Summary` protobuf对象。最后，  
为了将汇总后的数据写入磁盘，需要将汇总的protobuf传递给[tf.train.Summarywriter](../api_docs/python/train.md#SummaryWriter)。

`SummaryWriter`在自身的构造中包含了一个logdir。这个logdir是非常重要的，所有的事件都会写到这个文件夹里。此  
外，`SummaryWriter`中还包含了一个可选择的`GraphDef`选项。如果选择了这个选项，那么TensorBoard也会显示你的  
图像。

现在你已经修改了你的图，也有了`SummaryWriter`，你现在一个可以执行你的网络了！如果你愿意的话，你可以一步一  
步的执行整合过的汇总操作，这样你会得到一大堆训练数据。这很有可能超过了你想要的数据量。因此，你可以整合为  
100步一记录，或者向下面的代码里示范的这样。

```python
merged_summary_op = tf.merge_all_summaries()
summary_writer = tf.train.SummaryWriter('/tmp/mnist_logs', sess.graph)
total_step = 0
while training:
  total_step += 1
  session.run(training_op)
  if total_step % 100 == 0:
    summary_str = session.run(merged_summary_op)
    summary_writer.add_summary(summary_str, total_step)
```
你现在已经用TensorBoard完全设置好可视化这些数据了。

#启动TensorBoard　<a class="md-anchor" id="AUTOGENERATED-launching-tensorboard"></a>
如果你想启动TensorBoard，就输入下面的指令
```
python tensorflow/tensorboard/tensorboard.py --logdir=path/to/log-directory
```
这里的`logdir`指向`SummaryWriter`存储数据的地址。如果这个`logdir`文件夹的下层文件夹包含了另一次运行时的数  
据，那么TensorBoard会显示所有运行的数据。一旦TensorBoard开始运行，你可以通过在浏览器中输入  
`localhost:6006`来访问TensorBoard。

如果你已经通过pip安装了TensorBoard，你可以通过执行更为简单地命令来访问TensorBoard
```
tensorboard --logdir=/path/to/log-directory
```
当我们在TensorBoard的界面时，你会在右上角看到导航选项卡，每一个标签代表一组可以显示的有序数据 。对于你查看  
的每一个选项，如果TensorBoard中没有数据与这个选项相关的话，则会显示一条如何排序才适用于这个选项的提示。

更多更详细的关于如何使用graph选项来显示你的图像的信息。参见[TensorBoard:图表可视化](./graph_viz.md)

原文地址：[TensorBoard:Visualizing Learning](http://tensorflow.org/how_tos/summaries_and_tensorboard/index.html#tensorboard-visualizing-learning) 翻译：[thylaco1eo](https://github.com/thylaco1eo) 校对：